{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29d738d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4230728",
   "metadata": {},
   "source": [
    "# 1. Scrape the details of most viewed videos on YouTube from Wikipedia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c041298",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4907a081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 ['\"Baby Shark Dance\"[6]', '\"Despacito\"[9]', '\"Johny Johny Yes Papa\"[17]', '\"Bath Song\"[18]', '\"Shape of You\"[19]', '\"See You Again\"[22]', '\"Wheels on the Bus\"[27]', '\"Phonics Song with Two Words\"[28]', '\"Uptown Funk\"[29]', '\"Learning Colors – Colorful Eggs on a Farm\"[30]', '\"Gangnam Style\"[31]', '\"Masha and the Bear – Recipe for Disaster\"[36]', '\"Dame Tu Cosita\"[37]', '\"Axel F\"[38]', '\"Sugar\"[39]', '\"Counting Stars\"[40]', '\"Baa Baa Black Sheep\"[41]', '\"Roar\"[42]', '\"Lakdi Ki Kathi\"[43]', '\"Waka Waka (This Time for Africa)\"[44]', '\"Sorry\"[45]', '\"Thinking Out Loud\"[46]', '\"Humpty the train on a fruits ride\"[47]', '\"Shree Hanuman Chalisa\"[48]', '\"Dark Horse\"[49]', '\"Perfect\"[50]', '\"Let Her Go\"[51]', '\"Faded\"[52]', '\"Girls Like You\"[53]', '\"Lean On\"[54]']\n"
     ]
    }
   ],
   "source": [
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_Date=[]\n",
    "Views=[]\n",
    "\n",
    "#scraping the Video Name \n",
    "nm=driver.find_elements(By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers col3center col4right jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "for i in nm:\n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "print(len(Name),Name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33627550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 [\"Pinkfong Baby Shark - Kids' Songs & Stories\", 'Luis Fonsi', \"LooLoo Kids - Nursery Rhymes and Children's Songs\", 'Cocomelon - Nursery Rhymes', 'Ed Sheeran', 'Wiz Khalifa', 'Cocomelon - Nursery Rhymes', 'ChuChu TV Nursery Rhymes & Kids Songs', 'Mark Ronson', 'Miroshka TV', 'Psy', 'Get Movies', 'Ultra Records', 'Crazy Frog', 'Maroon 5', 'OneRepublic', 'Cocomelon - Nursery Rhymes', 'Katy Perry', 'Jingle Toons', 'Shakira', 'Justin Bieber', 'Ed Sheeran', 'Kiddiestv Hindi - Nursery Rhymes & Kids Songs', 'T-Series Bhakti Sagar', 'Katy Perry', 'Ed Sheeran', 'Passenger', 'Alan Walker', 'Maroon 5', 'Major Lazer Official']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Artist \n",
    "Ar=driver.find_elements(By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers col3center col4right jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "for i in Ar:\n",
    "    if i.text is None :\n",
    "        Artist.append(\"--\") \n",
    "    else:\n",
    "        Artist.append(i.text)\n",
    "print(len(Artist),Artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "907ea9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 ['June 17, 2016', 'January 12, 2017', 'October 8, 2016', 'May 2, 2018', 'January 30, 2017', 'April 6, 2015', 'May 24, 2018', 'March 6, 2014', 'November 19, 2014', 'February 27, 2018', 'July 15, 2012', 'January 31, 2012', 'April 5, 2018', 'June 16, 2009', 'January 14, 2015', 'May 31, 2013', 'June 25, 2018', 'September 5, 2013', 'June 14, 2018', 'June 4, 2010', 'October 22, 2015', 'October 7, 2014', 'January 26, 2018', 'May 10, 2011', 'February 20, 2014', 'November 9, 2017', 'July 25, 2012', 'December 3, 2015', 'May 31, 2018', 'March 22, 2015']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Upload_Date \n",
    "date=driver.find_elements(By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers col3center col4right jquery-tablesorter\"]/tbody/tr/td[4]')\n",
    "for i in date:\n",
    "    if i.text is None :\n",
    "        Upload_Date.append(\"--\") \n",
    "    else:\n",
    "        Upload_Date.append(i.text)\n",
    "print(len(Upload_Date),Upload_Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "03c2dfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 ['14.09', '8.38', '6.87', '6.62', '6.20', '6.17', '5.88', '5.70', '5.15', '5.07', '5.05', '4.58', '4.55', '4.34', '4.00', '3.97', '3.96', '3.96', '3.91', '3.85', '3.77', '3.73', '3.73', '3.69', '3.67', '3.67', '3.61', '3.59', '3.56', '3.55']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Views \n",
    "v=driver.find_elements(By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers col3center col4right jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "for i in v:\n",
    "    if i.text is None :\n",
    "        Views.append(\"--\") \n",
    "    else:\n",
    "        Views.append(i.text)\n",
    "print(len(Views),Views)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a647d432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_Date</th>\n",
       "      <th>Views In Bllion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>14.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Johny Johny Yes Papa\"[17]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Bath Song\"[18]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Shape of You\"[19]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Phonics Song with Two Words\"[28]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Uptown Funk\"[29]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[30]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>5.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"Roar\"[42]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"Lakdi Ki Kathi\"[43]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[44]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\"Sorry\"[45]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\"Shree Hanuman Chalisa\"[48]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>May 10, 2011</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"Dark Horse\"[49]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\"Perfect\"[50]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"Let Her Go\"[51]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"Faded\"[52]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"Girls Like You\"[53]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"Lean On\"[54]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Video Title  \\\n",
       "0                             \"Baby Shark Dance\"[6]   \n",
       "1                                    \"Despacito\"[9]   \n",
       "2                        \"Johny Johny Yes Papa\"[17]   \n",
       "3                                   \"Bath Song\"[18]   \n",
       "4                                \"Shape of You\"[19]   \n",
       "5                               \"See You Again\"[22]   \n",
       "6                           \"Wheels on the Bus\"[27]   \n",
       "7                 \"Phonics Song with Two Words\"[28]   \n",
       "8                                 \"Uptown Funk\"[29]   \n",
       "9   \"Learning Colors – Colorful Eggs on a Farm\"[30]   \n",
       "10                              \"Gangnam Style\"[31]   \n",
       "11   \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
       "12                             \"Dame Tu Cosita\"[37]   \n",
       "13                                     \"Axel F\"[38]   \n",
       "14                                      \"Sugar\"[39]   \n",
       "15                             \"Counting Stars\"[40]   \n",
       "16                        \"Baa Baa Black Sheep\"[41]   \n",
       "17                                       \"Roar\"[42]   \n",
       "18                             \"Lakdi Ki Kathi\"[43]   \n",
       "19           \"Waka Waka (This Time for Africa)\"[44]   \n",
       "20                                      \"Sorry\"[45]   \n",
       "21                          \"Thinking Out Loud\"[46]   \n",
       "22          \"Humpty the train on a fruits ride\"[47]   \n",
       "23                      \"Shree Hanuman Chalisa\"[48]   \n",
       "24                                 \"Dark Horse\"[49]   \n",
       "25                                    \"Perfect\"[50]   \n",
       "26                                 \"Let Her Go\"[51]   \n",
       "27                                      \"Faded\"[52]   \n",
       "28                             \"Girls Like You\"[53]   \n",
       "29                                    \"Lean On\"[54]   \n",
       "\n",
       "                                               Artist        Upload_Date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                          Luis Fonsi   January 12, 2017   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                          Ed Sheeran   January 30, 2017   \n",
       "5                                         Wiz Khalifa      April 6, 2015   \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "8                                         Mark Ronson  November 19, 2014   \n",
       "9                                         Miroshka TV  February 27, 2018   \n",
       "10                                                Psy      July 15, 2012   \n",
       "11                                         Get Movies   January 31, 2012   \n",
       "12                                      Ultra Records      April 5, 2018   \n",
       "13                                         Crazy Frog      June 16, 2009   \n",
       "14                                           Maroon 5   January 14, 2015   \n",
       "15                                        OneRepublic       May 31, 2013   \n",
       "16                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "17                                         Katy Perry  September 5, 2013   \n",
       "18                                       Jingle Toons      June 14, 2018   \n",
       "19                                            Shakira       June 4, 2010   \n",
       "20                                      Justin Bieber   October 22, 2015   \n",
       "21                                         Ed Sheeran    October 7, 2014   \n",
       "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "23                              T-Series Bhakti Sagar       May 10, 2011   \n",
       "24                                         Katy Perry  February 20, 2014   \n",
       "25                                         Ed Sheeran   November 9, 2017   \n",
       "26                                          Passenger      July 25, 2012   \n",
       "27                                        Alan Walker   December 3, 2015   \n",
       "28                                           Maroon 5       May 31, 2018   \n",
       "29                               Major Lazer Official     March 22, 2015   \n",
       "\n",
       "   Views In Bllion  \n",
       "0            14.09  \n",
       "1             8.38  \n",
       "2             6.87  \n",
       "3             6.62  \n",
       "4             6.20  \n",
       "5             6.17  \n",
       "6             5.88  \n",
       "7             5.70  \n",
       "8             5.15  \n",
       "9             5.07  \n",
       "10            5.05  \n",
       "11            4.58  \n",
       "12            4.55  \n",
       "13            4.34  \n",
       "14            4.00  \n",
       "15            3.97  \n",
       "16            3.96  \n",
       "17            3.96  \n",
       "18            3.91  \n",
       "19            3.85  \n",
       "20            3.77  \n",
       "21            3.73  \n",
       "22            3.73  \n",
       "23            3.69  \n",
       "24            3.67  \n",
       "25            3.67  \n",
       "26            3.61  \n",
       "27            3.59  \n",
       "28            3.56  \n",
       "29            3.55  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Youtube_Video=pd.DataFrame([])\n",
    "\n",
    "Youtube_Video['Video Title']=Name\n",
    "Youtube_Video['Artist']=Artist\n",
    "Youtube_Video['Upload_Date']=Upload_Date\n",
    "Youtube_Video['Views In Bllion']=Views\n",
    "Youtube_Video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbc1444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1071b79e",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6296705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.bcci.tv/fixtures?platform=international&type=men\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f109505a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 ['ENGLAND TOUR OF INDIA 2023-24', 'ENGLAND TOUR OF INDIA 2023-24', 'INDIA TOUR OF ZIMBABWE 2024', 'INDIA TOUR OF ZIMBABWE 2024', 'INDIA TOUR OF ZIMBABWE 2024', 'INDIA TOUR OF ZIMBABWE 2024', 'INDIA TOUR OF ZIMBABWE 2024']\n"
     ]
    }
   ],
   "source": [
    "Team=[]\n",
    "Date_Time =[]\n",
    "Ground=[]\n",
    "Test_ODI=[]\n",
    "\n",
    "\n",
    "#scraping the company_name \n",
    "tm=driver.find_elements(By.XPATH, '//div[@class=\"match-info\"]/h5')\n",
    "for i in tm:\n",
    "    if i.text is None :\n",
    "        Team.append(\"--\") \n",
    "    else:\n",
    "        Team.append(i.text)\n",
    "print(len(Team),Team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6192b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 ['23 FEBRUARY, 2024', '7 MARCH, 2024', '6 JULY, 2024', '7 JULY, 2024', '10 JULY, 2024', '13 JULY, 2024', '14 JULY, 2024']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Date_Time \n",
    "DT=driver.find_elements(By.XPATH, '//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in DT:\n",
    "    if i.text is None :\n",
    "        Date_Time.append(\"--\") \n",
    "    else:\n",
    "        Date_Time.append(i.text)\n",
    "print(len(Date_Time),Date_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e40b0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 ['JSCA International Stadium Complex,', 'Himachal Pradesh Cricket Association Stadium,', 'Harare Sports Club,', 'Harare Sports Club,', 'Harare Sports Club,', 'Harare Sports Club,', 'Harare Sports Club,']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Ground \n",
    "G=driver.find_elements(By.XPATH, '//span[@class=\"ng-binding ng-scope\"]')\n",
    "for i in G:\n",
    "    if i.text is None :\n",
    "        Ground.append(\"--\") \n",
    "    else:\n",
    "        Ground.append(i.text)\n",
    "print(len(Ground),Ground)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a2b1f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JSCA International Stadium Complex, - Ranchi', 'Himachal Pradesh Cricket Association Stadium, - Dharamsala', 'Harare Sports Club, - Harare', 'Harare Sports Club, - Harare', 'Harare Sports Club, - Harare', 'Harare Sports Club, - Harare', 'Harare Sports Club, - Harare']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Find elements with class name \"ground-name\"\n",
    "ground_names = driver.find_elements(By.XPATH, '//span[@class=\"ng-binding ng-scope\"]')\n",
    "\n",
    "# Find elements with class name \"city-name\"\n",
    "city_names = driver.find_elements(By.XPATH, '//span[@class=\"ng-binding\"]')\n",
    "\n",
    "# Concatenate ground names and city names\n",
    "concatenated_list = []\n",
    "for ground, city in zip(ground_names, city_names):\n",
    "    concatenated_list.append(f\"{ground.text} - {city.text}\")\n",
    "\n",
    "# Print or use the concatenated text\n",
    "print(concatenated_list)\n",
    "\n",
    "\n",
    "#G2=driver.find_elements(By.XPATH, '//span[@class=\"ng-binding\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a10a787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 ['4th Test', '5th Test', '1st T20I', '2nd T20I', '3rd T20I', '4th T20I', '5th T20I']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Test_ODI \n",
    "TO=driver.find_elements(By.XPATH, '//div[@class=\"tags-wrap\"]/span[1]')\n",
    "for i in TO:\n",
    "    if i.text is None :\n",
    "        Test_ODI.append(\"--\") \n",
    "    else:\n",
    "        Test_ODI.append(i.text)\n",
    "print(len(Test_ODI),Test_ODI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff40ca89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Series</th>\n",
       "      <th>Ground</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>23 FEBRUARY, 2024</td>\n",
       "      <td>4th Test</td>\n",
       "      <td>JSCA International Stadium Complex, - Ranchi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>7 MARCH, 2024</td>\n",
       "      <td>5th Test</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>6 JULY, 2024</td>\n",
       "      <td>1st T20I</td>\n",
       "      <td>Harare Sports Club, - Harare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>7 JULY, 2024</td>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>Harare Sports Club, - Harare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>10 JULY, 2024</td>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>Harare Sports Club, - Harare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>13 JULY, 2024</td>\n",
       "      <td>4th T20I</td>\n",
       "      <td>Harare Sports Club, - Harare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>14 JULY, 2024</td>\n",
       "      <td>5th T20I</td>\n",
       "      <td>Harare Sports Club, - Harare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Team          Date_Time    Series  \\\n",
       "0  ENGLAND TOUR OF INDIA 2023-24  23 FEBRUARY, 2024  4th Test   \n",
       "1  ENGLAND TOUR OF INDIA 2023-24      7 MARCH, 2024  5th Test   \n",
       "2    INDIA TOUR OF ZIMBABWE 2024       6 JULY, 2024  1st T20I   \n",
       "3    INDIA TOUR OF ZIMBABWE 2024       7 JULY, 2024  2nd T20I   \n",
       "4    INDIA TOUR OF ZIMBABWE 2024      10 JULY, 2024  3rd T20I   \n",
       "5    INDIA TOUR OF ZIMBABWE 2024      13 JULY, 2024  4th T20I   \n",
       "6    INDIA TOUR OF ZIMBABWE 2024      14 JULY, 2024  5th T20I   \n",
       "\n",
       "                                              Ground  \n",
       "0       JSCA International Stadium Complex, - Ranchi  \n",
       "1  Himachal Pradesh Cricket Association Stadium, ...  \n",
       "2                       Harare Sports Club, - Harare  \n",
       "3                       Harare Sports Club, - Harare  \n",
       "4                       Harare Sports Club, - Harare  \n",
       "5                       Harare Sports Club, - Harare  \n",
       "6                       Harare Sports Club, - Harare  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "International_Fixtures=pd.DataFrame([])\n",
    "International_Fixtures['Team']=Team\n",
    "International_Fixtures['Date_Time']=Date_Time\n",
    "International_Fixtures['Series']=Test_ODI\n",
    "International_Fixtures['Ground']=concatenated_list\n",
    "International_Fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be435d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fc45bcd",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of State-wise GDP of India from statisticstime.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9bd5a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "12478bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "State =[]\n",
    "GDP=[]\n",
    "GSDP_Current=[]\n",
    "GSDP_Previous=[]\n",
    "Share=[]\n",
    "\n",
    "\n",
    "economy = driver.find_element(By.XPATH, '//*[@id=\"top\"]/div[2]/div[2]/button')       # Locating page foe top videos by xpath\n",
    "economy.click()\n",
    "\n",
    "\n",
    "ind = driver.find_element(By.XPATH, '//div[@class=\"dropdown-content\"]/a[3]')       # Locating page foe top videos by xpath\n",
    "ind.click()\n",
    "\n",
    "\n",
    "gdp = driver.find_element(By.XPATH, '//html/body/div[2]/div[2]/div[2]/ul/li[1]/a')       # Locating page foe top videos by xpath\n",
    "gdp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e68a263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Rank \n",
    "r=driver.find_elements(By.XPATH, \"//td[@class='data1']\")\n",
    "for i in r:\n",
    "    if i.text is None :\n",
    "        Rank.append(\"--\") \n",
    "    else:\n",
    "        Rank.append(i.text)\n",
    "print(len(Rank),Rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a757816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 ['Maharashtra', 'Tamil Nadu', 'Uttar Pradesh', 'Karnataka', 'Gujarat', 'West Bengal', 'Rajasthan', 'Madhya Pradesh', 'Andhra Pradesh', 'Telangana', 'Kerala', 'Delhi', 'Haryana', 'Odisha', 'Bihar', 'Punjab', 'Assam', 'Chhattisgarh', 'Jharkhand', 'Uttarakhand', 'Jammu & Kashmir-UT', 'Himachal Pradesh', 'Goa', 'Tripura', 'Chandigarh', 'Puducherry', 'Meghalaya', 'Sikkim', 'Manipur', 'Arunachal Pradesh', 'Nagaland', 'Mizoram', 'Andaman & Nicobar Islands', 'India', 'Maharashtra', 'Tamil Nadu', 'Karnataka', 'Uttar Pradesh', 'Gujarat', 'West Bengal', 'Rajasthan', 'Madhya Pradesh', 'Telangana', 'Andhra Pradesh', 'Kerala', 'Delhi', 'Haryana', 'Bihar', 'Odisha', 'Punjab', 'Assam', 'Chhattisgarh', 'Jharkhand', 'Uttarakhand', 'Jammu & Kashmir-UT', 'Himachal Pradesh', 'Goa', 'Tripura', 'Chandigarh', 'Puducherry', 'Meghalaya', 'Manipur', 'Arunachal Pradesh', 'Sikkim', 'Nagaland', 'Mizoram', 'Andaman & Nicobar Islands', 'India']\n"
     ]
    }
   ],
   "source": [
    "#scraping the State \n",
    "St=driver.find_elements(By.XPATH, \"//td[@class='name']\")\n",
    "for i in St:\n",
    "    if i.text is None :\n",
    "        State.append(\"--\") \n",
    "    else:\n",
    "        State.append(i.text)\n",
    "print(len(State),State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ce22065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['417.163', '278.011', '265.024', '263.440', '259.996', '183.068', '163.507', '152.494', '152.185', '151.523', '125.157', '121.422', '116.862', '90.047', '87.284', '82.442', '55.381', '54.550', '48.167', '36.530', '26.833', '23.659', '11.087', '8.396', '6.125', '5.938', '5.206', '5.041', '4.912', '4.714', '4.283', '3.735', '1.392']\n"
     ]
    }
   ],
   "source": [
    "#scraping the GDP \n",
    "gdp=driver.find_elements(By.XPATH, \"//*[@id='table_id']/tbody/tr/td[6]\")\n",
    "for i in gdp:\n",
    "    if i.text is None :\n",
    "        GDP.append(\"--\") \n",
    "    else:\n",
    "        GDP.append(i.text)\n",
    "print(len(GDP),GDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9be63841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['13.24%', '8.82%', '8.41%', '8.36%', '8.25%', '5.81%', '5.19%', '4.84%', '4.83%', '4.81%', '3.97%', '3.85%', '3.71%', '2.86%', '2.77%', '2.62%', '1.76%', '1.73%', '1.53%', '1.16%', '0.85%', '0.75%', '0.35%', '0.27%', '0.19%', '0.19%', '0.17%', '0.16%', '0.16%', '0.15%', '0.14%', '0.12%', '0.04%']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Share \n",
    "shr=driver.find_elements(By.XPATH, \"//*[@id='table_id']/tbody/tr/td[5]\")\n",
    "for i in shr:\n",
    "    if i.text is None :\n",
    "        Share.append(\"--\") \n",
    "    else:\n",
    "        Share.append(i.text)\n",
    "print(len(Share),Share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7d0bef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['3,108,022', '2,071,286', '1,974,532', '1,962,725', '1,937,066', '1,363,926', '1,218,193', '1,136,137', '1,133,837', '1,128,907', '932,470', '904,642', '870,665', '670,881', '650,302', '614,227', '412,612', '406,416', '358,863', '272,159', '199,917', '176,269', '82,604', '62,550', '45,635', '44,238', '38,785', '37,557', '36,594', '35,124', '31,913', '27,824', '10,371']\n"
     ]
    }
   ],
   "source": [
    "#scraping the GSDP_Current \n",
    "shr=driver.find_elements(By.XPATH, \"//*[@id='table_id']/tbody/tr/td[4]\")\n",
    "for i in shr:\n",
    "    if i.text is None :\n",
    "        GSDP_Current.append(\"--\") \n",
    "    else:\n",
    "        GSDP_Current.append(i.text)\n",
    "print(len(GSDP_Current),GSDP_Current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84e80181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['2,027,971', '1,343,287', '1,204,660', '1,229,713', '1,372,204', '787,758', '738,922', '600,689', '704,889', '674,371', '572,747', '597,765', '568,086', '432,960', '399,930', '433,769', '262,523', '267,681', '243,348', '193,412', '124,728', '126,433', '55,548', '39,487', '30,287', '27,834', '24,267', '20,728', '20,515', '19,801', '18,363', '18,494', '7,172']\n"
     ]
    }
   ],
   "source": [
    "#scraping the GSDP_Previous \n",
    "shr=driver.find_elements(By.XPATH, \"//*[@id='table_id']/tbody/tr/td[8]\")\n",
    "for i in shr:\n",
    "    if i.text is None :\n",
    "        GSDP_Previous.append(\"--\") \n",
    "    else:\n",
    "        GSDP_Previous.append(i.text)\n",
    "print(len(GSDP_Previous),GSDP_Previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "787d86da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>Share In GDP</th>\n",
       "      <th>GDP of State $</th>\n",
       "      <th>GSDP_Current</th>\n",
       "      <th>GSDP_Previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>13.24%</td>\n",
       "      <td>417.163</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>2,027,971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>8.82%</td>\n",
       "      <td>278.011</td>\n",
       "      <td>2,071,286</td>\n",
       "      <td>1,343,287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>8.41%</td>\n",
       "      <td>265.024</td>\n",
       "      <td>1,974,532</td>\n",
       "      <td>1,204,660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>8.36%</td>\n",
       "      <td>263.440</td>\n",
       "      <td>1,962,725</td>\n",
       "      <td>1,229,713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>8.25%</td>\n",
       "      <td>259.996</td>\n",
       "      <td>1,937,066</td>\n",
       "      <td>1,372,204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>5.81%</td>\n",
       "      <td>183.068</td>\n",
       "      <td>1,363,926</td>\n",
       "      <td>787,758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>5.19%</td>\n",
       "      <td>163.507</td>\n",
       "      <td>1,218,193</td>\n",
       "      <td>738,922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>4.84%</td>\n",
       "      <td>152.494</td>\n",
       "      <td>1,136,137</td>\n",
       "      <td>600,689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>4.83%</td>\n",
       "      <td>152.185</td>\n",
       "      <td>1,133,837</td>\n",
       "      <td>704,889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>4.81%</td>\n",
       "      <td>151.523</td>\n",
       "      <td>1,128,907</td>\n",
       "      <td>674,371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>3.97%</td>\n",
       "      <td>125.157</td>\n",
       "      <td>932,470</td>\n",
       "      <td>572,747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>3.85%</td>\n",
       "      <td>121.422</td>\n",
       "      <td>904,642</td>\n",
       "      <td>597,765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>3.71%</td>\n",
       "      <td>116.862</td>\n",
       "      <td>870,665</td>\n",
       "      <td>568,086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>2.86%</td>\n",
       "      <td>90.047</td>\n",
       "      <td>670,881</td>\n",
       "      <td>432,960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>2.77%</td>\n",
       "      <td>87.284</td>\n",
       "      <td>650,302</td>\n",
       "      <td>399,930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>82.442</td>\n",
       "      <td>614,227</td>\n",
       "      <td>433,769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1.76%</td>\n",
       "      <td>55.381</td>\n",
       "      <td>412,612</td>\n",
       "      <td>262,523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>1.73%</td>\n",
       "      <td>54.550</td>\n",
       "      <td>406,416</td>\n",
       "      <td>267,681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>1.53%</td>\n",
       "      <td>48.167</td>\n",
       "      <td>358,863</td>\n",
       "      <td>243,348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>36.530</td>\n",
       "      <td>272,159</td>\n",
       "      <td>193,412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir-UT</td>\n",
       "      <td>0.85%</td>\n",
       "      <td>26.833</td>\n",
       "      <td>199,917</td>\n",
       "      <td>124,728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>0.75%</td>\n",
       "      <td>23.659</td>\n",
       "      <td>176,269</td>\n",
       "      <td>126,433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>0.35%</td>\n",
       "      <td>11.087</td>\n",
       "      <td>82,604</td>\n",
       "      <td>55,548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>8.396</td>\n",
       "      <td>62,550</td>\n",
       "      <td>39,487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>6.125</td>\n",
       "      <td>45,635</td>\n",
       "      <td>30,287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.938</td>\n",
       "      <td>44,238</td>\n",
       "      <td>27,834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>0.17%</td>\n",
       "      <td>5.206</td>\n",
       "      <td>38,785</td>\n",
       "      <td>24,267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.041</td>\n",
       "      <td>37,557</td>\n",
       "      <td>20,728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>4.912</td>\n",
       "      <td>36,594</td>\n",
       "      <td>20,515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.714</td>\n",
       "      <td>35,124</td>\n",
       "      <td>19,801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.283</td>\n",
       "      <td>31,913</td>\n",
       "      <td>18,363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.735</td>\n",
       "      <td>27,824</td>\n",
       "      <td>18,494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.392</td>\n",
       "      <td>10,371</td>\n",
       "      <td>7,172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State Share In GDP GDP of State $ GSDP_Current  \\\n",
       "0     1                Maharashtra       13.24%        417.163    3,108,022   \n",
       "1     2                 Tamil Nadu        8.82%        278.011    2,071,286   \n",
       "2     3              Uttar Pradesh        8.41%        265.024    1,974,532   \n",
       "3     4                  Karnataka        8.36%        263.440    1,962,725   \n",
       "4     5                    Gujarat        8.25%        259.996    1,937,066   \n",
       "5     6                West Bengal        5.81%        183.068    1,363,926   \n",
       "6     7                  Rajasthan        5.19%        163.507    1,218,193   \n",
       "7     8             Madhya Pradesh        4.84%        152.494    1,136,137   \n",
       "8     9             Andhra Pradesh        4.83%        152.185    1,133,837   \n",
       "9    10                  Telangana        4.81%        151.523    1,128,907   \n",
       "10   11                     Kerala        3.97%        125.157      932,470   \n",
       "11   12                      Delhi        3.85%        121.422      904,642   \n",
       "12   13                    Haryana        3.71%        116.862      870,665   \n",
       "13   14                     Odisha        2.86%         90.047      670,881   \n",
       "14   15                      Bihar        2.77%         87.284      650,302   \n",
       "15   16                     Punjab        2.62%         82.442      614,227   \n",
       "16   17                      Assam        1.76%         55.381      412,612   \n",
       "17   18               Chhattisgarh        1.73%         54.550      406,416   \n",
       "18   19                  Jharkhand        1.53%         48.167      358,863   \n",
       "19   20                Uttarakhand        1.16%         36.530      272,159   \n",
       "20   21         Jammu & Kashmir-UT        0.85%         26.833      199,917   \n",
       "21   22           Himachal Pradesh        0.75%         23.659      176,269   \n",
       "22   23                        Goa        0.35%         11.087       82,604   \n",
       "23   24                    Tripura        0.27%          8.396       62,550   \n",
       "24   25                 Chandigarh        0.19%          6.125       45,635   \n",
       "25   26                 Puducherry        0.19%          5.938       44,238   \n",
       "26   27                  Meghalaya        0.17%          5.206       38,785   \n",
       "27   28                     Sikkim        0.16%          5.041       37,557   \n",
       "28   29                    Manipur        0.16%          4.912       36,594   \n",
       "29   30          Arunachal Pradesh        0.15%          4.714       35,124   \n",
       "30   31                   Nagaland        0.14%          4.283       31,913   \n",
       "31   32                    Mizoram        0.12%          3.735       27,824   \n",
       "32   33  Andaman & Nicobar Islands        0.04%          1.392       10,371   \n",
       "\n",
       "   GSDP_Previous  \n",
       "0      2,027,971  \n",
       "1      1,343,287  \n",
       "2      1,204,660  \n",
       "3      1,229,713  \n",
       "4      1,372,204  \n",
       "5        787,758  \n",
       "6        738,922  \n",
       "7        600,689  \n",
       "8        704,889  \n",
       "9        674,371  \n",
       "10       572,747  \n",
       "11       597,765  \n",
       "12       568,086  \n",
       "13       432,960  \n",
       "14       399,930  \n",
       "15       433,769  \n",
       "16       262,523  \n",
       "17       267,681  \n",
       "18       243,348  \n",
       "19       193,412  \n",
       "20       124,728  \n",
       "21       126,433  \n",
       "22        55,548  \n",
       "23        39,487  \n",
       "24        30,287  \n",
       "25        27,834  \n",
       "26        24,267  \n",
       "27        20,728  \n",
       "28        20,515  \n",
       "29        19,801  \n",
       "30        18,363  \n",
       "31        18,494  \n",
       "32         7,172  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "State_GDP=pd.DataFrame([])\n",
    "State_GDP['Rank']=Rank[:33]\n",
    "State_GDP['State']=State[:33]\n",
    "State_GDP['Share In GDP']=Share[:33]\n",
    "State_GDP['GDP of State $']=GDP[:33]\n",
    "State_GDP['GSDP_Current']=GSDP_Current[:33]\n",
    "State_GDP['GSDP_Previous']=GSDP_Previous[:33]\n",
    "State_GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c7b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4b96895",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of trending repositories on Github.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ad612424",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "249a9ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository_Name =[]\n",
    "Language=[]\n",
    "Muted_Link=[]\n",
    "\n",
    "explore = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')       \n",
    "explore.click()\n",
    "\n",
    "trending = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6f45eaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['charlax /', 'I-S00N /', 'chatchat-space /', 'GopeedLab /', 'krahets /', '1Panel-dev /', 'Kalabasa /', 'zhayujie /', 'FujiwaraChoki /', 'ChatGPTNextWeb /', 'karpathy /', 'maybe-finance /', 'codecrafters-io /', 'QuivrHQ /', 'mut-ex /', 'sherlock-project /', 'rustdesk /', 'songquanpeng /', 'LargeWorldModel /', 'xtekky /', 'jlevy /', 'tw93 /', 'oddfar /', 'facebookresearch /', 'lobehub /']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Repositor_Name \n",
    "RN=driver.find_elements(By.XPATH, \"//span[@class='text-normal']\")\n",
    "for i in RN:\n",
    "    if i.text is None :\n",
    "        Repository_Name.append(\"--\") \n",
    "    else:\n",
    "        Repository_Name.append(i.text)\n",
    "print(len(Repository_Name),Repository_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "00bcbd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 ['A collection of learning resources for curious software engineers', 'Langchain-Chatchat（原Langchain-ChatGLM）基于 Langchain 与 ChatGLM 等语言模型的本地知识库问答 | Langchain-Chatchat (formerly langchain-ChatGLM), local knowledge based LLM (like ChatGLM) QA app with langchain', 'A modern download manager that supports all platforms. Built with Golang and Flutter.', '《Hello 算法》：动画图解、一键运行的数据结构与算法教程，支持 Python, C++, Java, C#, Go, Swift, JS, TS, Dart, Rust, C, Zig 等语言。English edition ongoing', '🔥 🔥 🔥 现代化、开源的 Linux 服务器运维管理面板。', 'html with targeted manipulation zones', '基于大模型搭建的微信聊天机器人，同时支持微信、企业微信、公众号、飞书、钉钉接入，可选择GPT3.5/GPT4.0/Claude/文心一言/讯飞星火/通义千问/Gemini/GLM-4/LinkAI，能处理文本、语音和图片，访问操作系统和互联网，支持基于自有知识库进行定制企业智能客服。', 'Automate the process of making money online.', 'A cross-platform ChatGPT/Gemini UI (Web / PWA / Linux / Win / MacOS). 一键拥有你自己的跨平台 ChatGPT/Gemini 应用。', 'Minimal, clean code for the Byte Pair Encoding (BPE) algorithm commonly used in LLM tokenization.', 'The OS for your personal finances', 'Master programming by recreating your favorite technologies from scratch.', 'Your GenAI Second Brain 🧠 A personal productivity assistant (RAG) ⚡️🤖 Chat with your docs (PDF, CSV, ...) & apps using Langchain, GPT 3.5 / 4 turbo, Private, Anthropic, VertexAI, Ollama, LLMs, that you can share with users ! Local & Private alternative to OpenAI GPTs & ChatGPT powered by retrieval-augmented generation.', 'An intuitive GUI for GLIGEN that uses ComfyUI in the backend', '🔎 Hunt down social media accounts by username across social networks', 'An open-source remote desktop, and alternative to TeamViewer.', 'OpenAI 接口管理 & 分发系统，支持 Azure、Anthropic Claude、Google PaLM 2 & Gemini、智谱 ChatGLM、百度文心一言、讯飞星火认知、阿里通义千问、360 智脑以及腾讯混元，可用于二次分发管理 key，仅单可执行文件，已打包好 Docker 镜像，一键部署，开箱即用. OpenAI key management & redistribution system, using a single API for all LLMs, and features an English UI.', 'The official gpt4free repository | various collection of powerful language models', 'Master the command line, in one page', '🤱🏻 Turn any webpage into a desktop app with Rust. 🤱🏻 利用 Rust 轻松构建轻量级多端桌面应用', 'i茅台app自动预约，每日自动预约，支持docker一键部署', 'PyTorch code and models for V-JEPA self-supervised learning from video.', '🤖 Lobe Chat - an open-source, high-performance AI Chat framework. Support one-click free deployment of your private ChatGPT/Gemini/Ollama application.']\n"
     ]
    }
   ],
   "source": [
    "Description=[]\n",
    "#scraping the Description \n",
    "des=driver.find_elements(By.XPATH, '//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for i in des:\n",
    "    if i.text is None :\n",
    "        Description.append(\"--\") \n",
    "    else:\n",
    "        Description.append(i.text)\n",
    "print(len(Description),Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d921d663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 ['Python', 'Python', 'Dart', 'Java', 'Go', 'JavaScript', 'Python', 'Python', 'TypeScript', 'Python', 'Ruby', 'TypeScript', 'JavaScript', 'Python', 'Rust', 'JavaScript', 'Python', 'Python', 'Rust', 'Java', 'Python', 'TypeScript']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Language \n",
    "L=driver.find_elements(By.XPATH, \"//span[@itemprop='programmingLanguage']\")\n",
    "for i in L:\n",
    "    if i.text is None :\n",
    "        Language.append(\"NAN\") \n",
    "    else:\n",
    "        Language.append(i.text)\n",
    "print(len(Language),Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "44ca59d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 ['40,233', '3,088', '3,722', '1,791', '22,822', '3,966', '9,837', '756', '63,433', '7,722', '15,902', '1,423', '1,213', '25', '21,914', '6,070', '786', '91', '61,729', '51,524', '6,527', '497', '24,053', '1,777', '246,494', '23,420', '28,377', '2,731', '796', '73', '48,712', '5,892', '59,840', '6,301', '10,029', '2,362', '5,493', '428', '53,478', '12,310', '145,468', '13,996', '21,696', '3,123', '2,911', '830', '1,399', '119', '18,491', '3,716']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Muted_Link And Star \n",
    "ml=driver.find_elements(By.XPATH, '//a[@class=\"Link Link--muted d-inline-block mr-3\"]')\n",
    "for i in ml:\n",
    "    if i.text is None :\n",
    "        Muted_Link.append(\"NAN\") \n",
    "    else:\n",
    "        Muted_Link.append(i.text)\n",
    "print(len(Muted_Link),Muted_Link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8aecf53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['3,088', '1,791', '3,966', '756', '7,722', '1,423', '25', '6,070', '91', '51,524', '497', '1,777', '23,420', '2,731', '73', '5,892', '6,301', '2,362', '428', '12,310', '13,996', '3,123', '830', '119', '3,716']\n"
     ]
    }
   ],
   "source": [
    "Muted=[]\n",
    "for i in range(1,len(Muted_Link),2):\n",
    "    Muted.append(Muted_Link[i])\n",
    "    \n",
    "print(len(Muted),Muted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2f3bdc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['40,233', '3,722', '22,822', '9,837', '63,433', '15,902', '1,213', '21,914', '786', '61,729', '6,527', '24,053', '246,494', '28,377', '796', '48,712', '59,840', '10,029', '5,493', '53,478', '145,468', '21,696', '2,911', '1,399', '18,491']\n"
     ]
    }
   ],
   "source": [
    "Muted_Star=[]\n",
    "for i in range(0,len(Muted_Link),2):\n",
    "    Muted_Star.append(Muted_Link[i])\n",
    "    \n",
    "print(len(Muted_Star),Muted_Star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "68cccd46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Language</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Muted_Star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>charlax /</td>\n",
       "      <td>A collection of learning resources for curious...</td>\n",
       "      <td>Python</td>\n",
       "      <td>3,088</td>\n",
       "      <td>40,233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I-S00N /</td>\n",
       "      <td>Langchain-Chatchat（原Langchain-ChatGLM）基于 Langc...</td>\n",
       "      <td>Python</td>\n",
       "      <td>1,791</td>\n",
       "      <td>3,722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chatchat-space /</td>\n",
       "      <td>A modern download manager that supports all pl...</td>\n",
       "      <td>Dart</td>\n",
       "      <td>3,966</td>\n",
       "      <td>22,822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GopeedLab /</td>\n",
       "      <td>《Hello 算法》：动画图解、一键运行的数据结构与算法教程，支持 Python, C++,...</td>\n",
       "      <td>Java</td>\n",
       "      <td>756</td>\n",
       "      <td>9,837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>krahets /</td>\n",
       "      <td>🔥 🔥 🔥 现代化、开源的 Linux 服务器运维管理面板。</td>\n",
       "      <td>Go</td>\n",
       "      <td>7,722</td>\n",
       "      <td>63,433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1Panel-dev /</td>\n",
       "      <td>html with targeted manipulation zones</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>1,423</td>\n",
       "      <td>15,902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kalabasa /</td>\n",
       "      <td>基于大模型搭建的微信聊天机器人，同时支持微信、企业微信、公众号、飞书、钉钉接入，可选择GPT...</td>\n",
       "      <td>Python</td>\n",
       "      <td>25</td>\n",
       "      <td>1,213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zhayujie /</td>\n",
       "      <td>Automate the process of making money online.</td>\n",
       "      <td>Python</td>\n",
       "      <td>6,070</td>\n",
       "      <td>21,914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FujiwaraChoki /</td>\n",
       "      <td>A cross-platform ChatGPT/Gemini UI (Web / PWA ...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>91</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ChatGPTNextWeb /</td>\n",
       "      <td>Minimal, clean code for the Byte Pair Encoding...</td>\n",
       "      <td>Python</td>\n",
       "      <td>51,524</td>\n",
       "      <td>61,729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>karpathy /</td>\n",
       "      <td>The OS for your personal finances</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>497</td>\n",
       "      <td>6,527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>maybe-finance /</td>\n",
       "      <td>Master programming by recreating your favorite...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>1,777</td>\n",
       "      <td>24,053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>codecrafters-io /</td>\n",
       "      <td>Your GenAI Second Brain 🧠 A personal productiv...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>23,420</td>\n",
       "      <td>246,494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>QuivrHQ /</td>\n",
       "      <td>An intuitive GUI for GLIGEN that uses ComfyUI ...</td>\n",
       "      <td>Python</td>\n",
       "      <td>2,731</td>\n",
       "      <td>28,377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mut-ex /</td>\n",
       "      <td>🔎 Hunt down social media accounts by username ...</td>\n",
       "      <td>Rust</td>\n",
       "      <td>73</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sherlock-project /</td>\n",
       "      <td>An open-source remote desktop, and alternative...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>5,892</td>\n",
       "      <td>48,712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rustdesk /</td>\n",
       "      <td>OpenAI 接口管理 &amp; 分发系统，支持 Azure、Anthropic Claude、G...</td>\n",
       "      <td>Python</td>\n",
       "      <td>6,301</td>\n",
       "      <td>59,840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>songquanpeng /</td>\n",
       "      <td>The official gpt4free repository | various col...</td>\n",
       "      <td>Python</td>\n",
       "      <td>2,362</td>\n",
       "      <td>10,029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LargeWorldModel /</td>\n",
       "      <td>Master the command line, in one page</td>\n",
       "      <td>Rust</td>\n",
       "      <td>428</td>\n",
       "      <td>5,493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>xtekky /</td>\n",
       "      <td>🤱🏻 Turn any webpage into a desktop app with Ru...</td>\n",
       "      <td>Java</td>\n",
       "      <td>12,310</td>\n",
       "      <td>53,478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>jlevy /</td>\n",
       "      <td>i茅台app自动预约，每日自动预约，支持docker一键部署</td>\n",
       "      <td>Python</td>\n",
       "      <td>13,996</td>\n",
       "      <td>145,468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tw93 /</td>\n",
       "      <td>PyTorch code and models for V-JEPA self-superv...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>3,123</td>\n",
       "      <td>21,696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Repository Title                                        Description  \\\n",
       "0            charlax /  A collection of learning resources for curious...   \n",
       "1             I-S00N /  Langchain-Chatchat（原Langchain-ChatGLM）基于 Langc...   \n",
       "2     chatchat-space /  A modern download manager that supports all pl...   \n",
       "3          GopeedLab /  《Hello 算法》：动画图解、一键运行的数据结构与算法教程，支持 Python, C++,...   \n",
       "4            krahets /                     🔥 🔥 🔥 现代化、开源的 Linux 服务器运维管理面板。   \n",
       "5         1Panel-dev /              html with targeted manipulation zones   \n",
       "6           Kalabasa /  基于大模型搭建的微信聊天机器人，同时支持微信、企业微信、公众号、飞书、钉钉接入，可选择GPT...   \n",
       "7           zhayujie /       Automate the process of making money online.   \n",
       "8      FujiwaraChoki /  A cross-platform ChatGPT/Gemini UI (Web / PWA ...   \n",
       "9     ChatGPTNextWeb /  Minimal, clean code for the Byte Pair Encoding...   \n",
       "10          karpathy /                  The OS for your personal finances   \n",
       "11     maybe-finance /  Master programming by recreating your favorite...   \n",
       "12   codecrafters-io /  Your GenAI Second Brain 🧠 A personal productiv...   \n",
       "13           QuivrHQ /  An intuitive GUI for GLIGEN that uses ComfyUI ...   \n",
       "14            mut-ex /  🔎 Hunt down social media accounts by username ...   \n",
       "15  sherlock-project /  An open-source remote desktop, and alternative...   \n",
       "16          rustdesk /  OpenAI 接口管理 & 分发系统，支持 Azure、Anthropic Claude、G...   \n",
       "17      songquanpeng /  The official gpt4free repository | various col...   \n",
       "18   LargeWorldModel /               Master the command line, in one page   \n",
       "19            xtekky /  🤱🏻 Turn any webpage into a desktop app with Ru...   \n",
       "20             jlevy /                     i茅台app自动预约，每日自动预约，支持docker一键部署   \n",
       "21              tw93 /  PyTorch code and models for V-JEPA self-superv...   \n",
       "\n",
       "      Language Contributors Count  Muted_Star  \n",
       "0       Python               3,088     40,233  \n",
       "1       Python               1,791      3,722  \n",
       "2         Dart               3,966     22,822  \n",
       "3         Java                 756      9,837  \n",
       "4           Go               7,722     63,433  \n",
       "5   JavaScript               1,423     15,902  \n",
       "6       Python                  25      1,213  \n",
       "7       Python               6,070     21,914  \n",
       "8   TypeScript                  91        786  \n",
       "9       Python              51,524     61,729  \n",
       "10        Ruby                 497      6,527  \n",
       "11  TypeScript               1,777     24,053  \n",
       "12  JavaScript              23,420    246,494  \n",
       "13      Python               2,731     28,377  \n",
       "14        Rust                  73        796  \n",
       "15  JavaScript               5,892     48,712  \n",
       "16      Python               6,301     59,840  \n",
       "17      Python               2,362     10,029  \n",
       "18        Rust                 428      5,493  \n",
       "19        Java              12,310     53,478  \n",
       "20      Python              13,996    145,468  \n",
       "21  TypeScript               3,123     21,696  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trending_Repository=pd.DataFrame([])\n",
    "Trending_Repository['Repository Title']=Repository_Name[:22]\n",
    "Trending_Repository['Description']=Description[:22]\n",
    "Trending_Repository['Language']=Language[:22]\n",
    "Trending_Repository['Contributors Count ']=Muted[:22]\n",
    "Trending_Repository['Muted_Star']=Muted_Star[:22]\n",
    "Trending_Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e73813f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc17f199",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of top 100 songs on billiboard.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f58af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bede05fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Song_Name =[]\n",
    "Singer=[]\n",
    "rank=[]\n",
    "Last_Week=[]\n",
    "Weeks_on_board=[]\n",
    "Peak_pos=[]\n",
    "\n",
    "charts = driver.find_element(By.XPATH, '/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]')\n",
    "charts.click()\n",
    "\n",
    "top100 = driver.find_element(By.XPATH, '/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div/div[2]')      \n",
    "top100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8307f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Rank \n",
    "rb=driver.find_elements(By.XPATH, '//div[@class=\"o-chart-results-list-row-container\"]/ul[1]/li[1]/span[1]')\n",
    "for i in rb:\n",
    "    if i.text is None :\n",
    "        rank.append(\"--\") \n",
    "    else:\n",
    "        rank.append(i.text)\n",
    "print(len(rank),rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbc5d78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Lovin On Me', \"Texas Hold 'Em\", 'Carnival', 'Beautiful Things', 'Lose Control', 'Cruel Summer', 'Snooze', 'I Remember Everything', 'Greedy', 'Stick Season', 'Fast Car', 'Agora Hills', 'Water', 'Last Night', 'Redrum', \"Thinkin' Bout Me\", 'Flowers', \"Is It Over Now? (Taylor's Version) [From The Vault]\", 'Paint The Town Red', 'Yeah!', 'Never Lose Me', 'La Diabla', 'Fuk Sumn', 'Pretty Little Poison', 'Houdini', 'Back To Me', 'What Was I Made For?', 'Forever', 'Where The Wild Things Are', 'Talking', 'Yes, And?', 'Made For Me', 'Burn', 'Vultures', 'The Painter', 'Good Good', 'Selfish', '16 Carriages', 'Stars', 'Everybody', 'Rich Baby Daddy', 'Feather', 'Vampire', 'On My Mama', 'Wild Ones', 'Dance The Night', 'Save Me', 'Hiss', 'Exes', 'Need A Favor', 'Truck Bed', 'Do It', 'Paid', 'Surround Sound', 'Keys To My Life', 'World On Fire', 'First Person Shooter', 'La Victima', 'Get In With Me', 'Burn It Down', 'Standing Next To You', 'Think U The Shit (Fart)', 'Praise Jah In The Moonlight', 'Paperwork', 'Beg Forgiveness', 'Man Made A Bar', 'Hoodrat', 'One Call', 'Igual Que Un Angel', 'Spin You Around (1/24)', 'FTCU', 'One Of The Girls', 'Murder On The Dancefloor', 'You Broke My Heart', 'Northern Attitude', 'FE!N', '23', 'Bandit', 'Problematic', 'Nee-nah', 'Act II: Date @ 8', 'I Can Feel It', \"Mamaw's House\", 'Soak City', 'Harley Quinn', \"You're Gonna Go Far\", 'Bellakeo', 'IDGAF', 'Yeah Glo!', \"Different 'Round Here\", 'She Calls Me Back', \"We Don't Fight Anymore\", \"Good (Don't Die)\", 'King', 'Coal', 'Mmhmm', 'Monaco', 'Prove It', 'Perro Negro', 'Sunday Service']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Song_Name \n",
    "son=driver.find_elements(By.XPATH, '//div[@class=\"o-chart-results-list-row-container\"]/ul[1]/li[4]/ul/li/h3')\n",
    "for i in son:\n",
    "    if i.text is None :\n",
    "        Song_Name.append(\"--\") \n",
    "    else:\n",
    "        Song_Name.append(i.text)\n",
    "print(len(Song_Name),Song_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e751d198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Jack Harlow', 'Beyonce', '¥$: Kanye West & Ty Dolla $ign', 'Benson Boone', 'Teddy Swims', 'Taylor Swift', 'SZA', 'Zach Bryan Featuring Kacey Musgraves', 'Tate McRae', 'Noah Kahan', 'Luke Combs', 'Doja Cat', 'Tyla', 'Morgan Wallen', '21 Savage', 'Morgan Wallen', 'Miley Cyrus', 'Taylor Swift', 'Doja Cat', 'Usher Featuring Lil Jon & Ludacris', 'Flo Milli', 'Xavi', '¥$: Kanye West & Ty Dolla $ign', 'Warren Zeiders', 'Dua Lipa', '¥$: Kanye West & Ty Dolla $ign', 'Billie Eilish', 'Noah Kahan', 'Luke Combs', '¥$: Kanye West & Ty Dolla $ign Featuring North West', 'Ariana Grande', 'Muni Long', '¥$: Kanye West & Ty Dolla $ign', '¥$: Kanye West & Ty Dolla $ign Featuring Lil Durk & Bump J', 'Cody Johnson', 'Usher, Summer Walker & 21 Savage', 'Justin Timberlake', 'Beyonce', '¥$: Kanye West & Ty Dolla $ign', 'Nicki Minaj Featuring Lil Uzi Vert', 'Drake Featuring Sexyy Red & SZA', 'Sabrina Carpenter', 'Olivia Rodrigo', 'Victoria Monet', 'Jessie Murph & Jelly Roll', 'Dua Lipa', 'Jelly Roll With Lainey Wilson', 'Megan Thee Stallion', 'Tate McRae', 'Jelly Roll', 'HARDY', '¥$: Kanye West & Ty Dolla $ign', '¥$: Kanye West & Ty Dolla $ign', 'JID Featuring 21 Savage & Baby Tate', '¥$: Kanye West & Ty Dolla $ign', 'Nate Smith', 'Drake Featuring J. Cole', 'Xavi', 'BossMan Dlow', 'Parker McCollum', 'Jung Kook', 'Ice Spice', 'YG Marley', '¥$: Kanye West & Ty Dolla $ign', '¥$: Kanye West & Ty Dolla $ign', 'Morgan Wallen Featuring Eric Church', '¥$: Kanye West & Ty Dolla $ign', 'Rich Amiri', 'Kali Uchis & Peso Pluma', 'Morgan Wallen', 'Nicki Minaj', 'The Weeknd, Jennie & Lily Rose Depp', 'Sophie Ellis-Bextor', 'Drake', 'Noah Kahan With Hozier', 'Travis Scott Featuring Playboi Carti', 'Chayce Beckham', 'Don Toliver', '¥$: Kanye West & Ty Dolla $ign', '21 Savage, Travis Scott & Metro Boomin', '4Batz', 'Kane Brown', 'Thomas Rhett Featuring Morgan Wallen', '310babii', 'Fuerza Regida & Marshmello', 'Noah Kahan', 'Peso Pluma & Anitta', 'Drake Featuring Yeat', 'GloRilla', 'Riley Green Featuring Luke Combs', 'Noah Kahan With Kacey Musgraves', 'Carly Pearce Featuring Chris Stapleton', '¥$: Kanye West & Ty Dolla $ign', '¥$: Kanye West & Ty Dolla $ign', 'Dylan Gossett', 'BigXthaPlug', 'Bad Bunny', '21 Savage & Summer Walker', 'Bad Bunny & Feid', 'Latto']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Singer \n",
    "sin=driver.find_elements(By.XPATH, '//div[@class=\"o-chart-results-list-row-container\"]/ul[1]/li[4]/ul/li[1]/span[1]')\n",
    "for i in sin:\n",
    "    if i.text is None :\n",
    "        Singer.append(\"--\") \n",
    "    else:\n",
    "        Singer.append(i.text)\n",
    "print(len(Singer),Singer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76c30762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['1', '-', '-', '3', '2', '4', '5', '6', '7', '11', '8', '9', '12', '15', '14', '16', '10', '18', '17', '-', '19', '25', '-', '24', '22', '-', '20', '-', '26', '-', '21', '28', '-', '-', '30', '45', '23', '-', '-', '27', '32', '36', '29', '33', '35', '37', '40', '13', '34', '39', '46', '-', '-', '48', '-', '44', '47', '56', '68', '55', '81', '52', '60', '-', '-', '63', '-', '64', '53', '51', '54', '57', '59', '65', '97', '69', '74', '38', '-', '58', '61', '73', '78', '76', '67', '-', '70', '72', '-', '66', '-', '79', '-', '-', '86', '83', '77', '75', '82', '-']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Last_Week Rank \n",
    "lwr=driver.find_elements(By.XPATH, '//div[@class=\"o-chart-results-list-row-container\"]/ul[1]/li[4]/ul/li[4]/span[1]')\n",
    "for i in lwr:\n",
    "    if i.text is None :\n",
    "        Last_Week.append(\"--\") \n",
    "    else:\n",
    "        Last_Week.append(i.text)\n",
    "print(len(Last_Week),Last_Week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72c932c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['14', '1', '1', '4', '27', '41', '61', '25', '22', '20', '47', '21', '20', '55', '5', '50', '52', '16', '28', '46', '9', '9', '1', '23', '14', '1', '30', '1', '13', '1', '5', '5', '1', '1', '19', '27', '3', '1', '1', '10', '19', '11', '30', '22', '19', '33', '32', '3', '13', '44', '35', '1', '1', '14', '1', '16', '19', '9', '2', '17', '15', '3', '3', '1', '1', '21', '1', '3', '5', '3', '10', '8', '7', '13', '11', '16', '7', '2', '1', '5', '6', '7', '7', '9', '15', '1', '9', '19', '1', '11', '2', '9', '1', '1', '6', '8', '18', '5', '15', '1']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Weeks_on_board \n",
    "wob=driver.find_elements(By.XPATH, '//div[@class=\"o-chart-results-list-row-container\"]/ul[1]/li[4]/ul[1]/li[6]/span[1]')\n",
    "for i in wob:\n",
    "    if i.text is None :\n",
    "        Weeks_on_board.append(\"--\") \n",
    "    else:\n",
    "        Weeks_on_board.append(i.text)\n",
    "print(len(Weeks_on_board),Weeks_on_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4d2c940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['1', '2', '3', '3', '2', '1', '2', '1', '3', '10', '2', '7', '7', '1', '5', '7', '1', '1', '1', '1', '18', '20', '23', '24', '11', '26', '14', '28', '26', '30', '1', '28', '33', '34', '30', '25', '19', '38', '39', '24', '11', '36', '1', '33', '35', '6', '19', '1', '34', '13', '36', '52', '53', '40', '55', '21', '1', '46', '59', '52', '5', '37', '60', '64', '65', '15', '67', '64', '22', '24', '15', '57', '51', '11', '37', '5', '64', '38', '79', '10', '59', '59', '55', '61', '40', '86', '53', '2', '89', '60', '76', '67', '93', '94', '86', '65', '5', '43', '20', '100']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Peak position\n",
    "pp=driver.find_elements(By.XPATH, '//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[5]/span')\n",
    "for i in pp:\n",
    "    if i.text is None :\n",
    "        Peak_pos.append(\"--\") \n",
    "    else:\n",
    "        Peak_pos.append(i.text)\n",
    "print(len(Peak_pos),Peak_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac2eefeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last_Week_Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks_on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Lovin On Me</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Texas Hold 'Em</td>\n",
       "      <td>Beyonce</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Carnival</td>\n",
       "      <td>¥$: Kanye West &amp; Ty Dolla $ign</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Beautiful Things</td>\n",
       "      <td>Benson Boone</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Lose Control</td>\n",
       "      <td>Teddy Swims</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Mmhmm</td>\n",
       "      <td>BigXthaPlug</td>\n",
       "      <td>83</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Monaco</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>77</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Prove It</td>\n",
       "      <td>21 Savage &amp; Summer Walker</td>\n",
       "      <td>75</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Perro Negro</td>\n",
       "      <td>Bad Bunny &amp; Feid</td>\n",
       "      <td>82</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Sunday Service</td>\n",
       "      <td>Latto</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Peak_rank         Song Name                     Artist Name Last_Week_Rank  \\\n",
       "0          1       Lovin On Me                     Jack Harlow              1   \n",
       "1          2    Texas Hold 'Em                         Beyonce              -   \n",
       "2          3          Carnival  ¥$: Kanye West & Ty Dolla $ign              -   \n",
       "3          4  Beautiful Things                    Benson Boone              3   \n",
       "4          5      Lose Control                     Teddy Swims              2   \n",
       "..       ...               ...                             ...            ...   \n",
       "95        96             Mmhmm                     BigXthaPlug             83   \n",
       "96        97            Monaco                       Bad Bunny             77   \n",
       "97        98          Prove It       21 Savage & Summer Walker             75   \n",
       "98        99       Perro Negro                Bad Bunny & Feid             82   \n",
       "99       100    Sunday Service                           Latto              -   \n",
       "\n",
       "   Peak Rank Weeks_on_board  \n",
       "0          1             14  \n",
       "1          2              1  \n",
       "2          3              1  \n",
       "3          3              4  \n",
       "4          2             27  \n",
       "..       ...            ...  \n",
       "95        65              8  \n",
       "96         5             18  \n",
       "97        43              5  \n",
       "98        20             15  \n",
       "99       100              1  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_Song=pd.DataFrame([])\n",
    "Top_Song['Peak_rank']=rank\n",
    "Top_Song['Song Name']=Song_Name\n",
    "Top_Song['Artist Name']=Singer\n",
    "Top_Song['Last_Week_Rank']=Last_Week\n",
    "Top_Song['Peak Rank']=Peak_pos\n",
    "Top_Song['Weeks_on_board']=Weeks_on_board\n",
    "Top_Song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b0e0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28c4db3d",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of Highest selling novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8a5d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ea5ed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Da Vinci Code,The', 'Harry Potter and the Deathly Hallows', \"Harry Potter and the Philosopher's Stone\", 'Harry Potter and the Order of the Phoenix', 'Fifty Shades of Grey', 'Harry Potter and the Goblet of Fire', 'Harry Potter and the Chamber of Secrets', 'Harry Potter and the Prisoner of Azkaban', 'Angels and Demons', \"Harry Potter and the Half-blood Prince:Children's Edition\", 'Fifty Shades Darker', 'Twilight', 'Girl with the Dragon Tattoo,The:Millennium Trilogy', 'Fifty Shades Freed', 'Lost Symbol,The', 'New Moon', 'Deception Point', 'Eclipse', 'Lovely Bones,The', 'Curious Incident of the Dog in the Night-time,The', 'Digital Fortress', 'Short History of Nearly Everything,A', 'Girl Who Played with Fire,The:Millennium Trilogy', 'Breaking Dawn', 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar', 'Gruffalo,The', \"Jamie's 30-Minute Meals\", 'Kite Runner,The', 'One Day', 'Thousand Splendid Suns,A', \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\", \"Time Traveler's Wife,The\", 'Atonement', \"Bridget Jones's Diary:A Novel\", 'World According to Clarkson,The', \"Captain Corelli's Mandolin\", 'Sound of Laughter,The', 'Life of Pi', 'Billy Connolly', 'Child Called It,A', \"Gruffalo's Child,The\", \"Angela's Ashes:A Memoir of a Childhood\", 'Birdsong', 'Northern Lights:His Dark Materials S.', 'Labyrinth', 'Harry Potter and the Half-blood Prince', 'Help,The', 'Man and Boy', 'Memoirs of a Geisha', \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\", 'Island,The', 'PS, I Love You', 'You are What You Eat:The Plan That Will Change Your Life', 'Shadow of the Wind,The', 'Tales of Beedle the Bard,The', 'Broker,The', \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\", 'Subtle Knife,The:His Dark Materials S.', 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation', \"Delia's How to Cook:(Bk.1)\", 'Chocolat', 'Boy in the Striped Pyjamas,The', \"My Sister's Keeper\", 'Amber Spyglass,The:His Dark Materials S.', 'To Kill a Mockingbird', 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin', 'Dear Fatty', 'Short History of Tractors in Ukrainian,A', 'Hannibal', 'Lord of the Rings,The', 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio', 'Interpretation of Murder,The', 'Sharon Osbourne Extreme:My Autobiography', 'Alchemist,The:A Fable About Following Your Dream', \"At My Mother's Knee ...:and Other Low Joints\", 'Notes from a Small Island', 'Return of the Naked Chef,The', 'Bridget Jones: The Edge of Reason', \"Jamie's Italy\", 'I Can Make You Thin', 'Down Under', 'Summons,The', 'Small Island', 'Nigella Express', 'Brick Lane', \"Memory Keeper's Daughter,The\", 'Room on the Broom', 'About a Boy', 'My Booky Wook', 'God Delusion,The', '\"Beano\" Annual,The', 'White Teeth', 'House at Riverton,The', 'Book Thief,The', 'Nights of Rain and Stars', 'Ghost,The', 'Happy Days with the Naked Chef', 'Hunger Games,The:Hunger Games Trilogy', \"Lost Boy,The:A Foster Child's Search for the Love of a Family\", \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\"]\n"
     ]
    }
   ],
   "source": [
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "\n",
    "#scraping the Book_name \n",
    "bname=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[2]\")\n",
    "for i in bname:\n",
    "    if i.text is None :\n",
    "        Book_name.append(\"--\") \n",
    "    else:\n",
    "        Book_name.append(i.text)\n",
    "print(len(Book_name),Book_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fed0f700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Brown, Dan', 'Rowling, J.K.', 'Rowling, J.K.', 'Rowling, J.K.', 'James, E. L.', 'Rowling, J.K.', 'Rowling, J.K.', 'Rowling, J.K.', 'Brown, Dan', 'Rowling, J.K.', 'James, E. L.', 'Meyer, Stephenie', 'Larsson, Stieg', 'James, E. L.', 'Brown, Dan', 'Meyer, Stephenie', 'Brown, Dan', 'Meyer, Stephenie', 'Sebold, Alice', 'Haddon, Mark', 'Brown, Dan', 'Bryson, Bill', 'Larsson, Stieg', 'Meyer, Stephenie', 'Carle, Eric', 'Donaldson, Julia', 'Oliver, Jamie', 'Hosseini, Khaled', 'Nicholls, David', 'Hosseini, Khaled', 'Larsson, Stieg', 'Niffenegger, Audrey', 'McEwan, Ian', 'Fielding, Helen', 'Clarkson, Jeremy', 'Bernieres, Louis de', 'Kay, Peter', 'Martel, Yann', 'Stephenson, Pamela', 'Pelzer, Dave', 'Donaldson, Julia', 'McCourt, Frank', 'Faulks, Sebastian', 'Pullman, Philip', 'Mosse, Kate', 'Rowling, J.K.', 'Stockett, Kathryn', 'Parsons, Tony', 'Golden, Arthur', 'McCall Smith, Alexander', 'Hislop, Victoria', 'Ahern, Cecelia', 'McKeith, Gillian', 'Zafon, Carlos Ruiz', 'Rowling, J.K.', 'Grisham, John', 'Atkins, Robert C.', 'Pullman, Philip', 'Truss, Lynne', 'Smith, Delia', 'Harris, Joanne', 'Boyne, John', 'Picoult, Jodi', 'Pullman, Philip', 'Lee, Harper', 'Gray, John', 'French, Dawn', 'Lewycka, Marina', 'Harris, Thomas', 'Tolkien, J. R. R.', 'Moore, Michael', 'Rubenfeld, Jed', 'Osbourne, Sharon', 'Coelho, Paulo', \"O'Grady, Paul\", 'Bryson, Bill', 'Oliver, Jamie', 'Fielding, Helen', 'Oliver, Jamie', 'McKenna, Paul', 'Bryson, Bill', 'Grisham, John', 'Levy, Andrea', 'Lawson, Nigella', 'Ali, Monica', 'Edwards, Kim', 'Donaldson, Julia', 'Hornby, Nick', 'Brand, Russell', 'Dawkins, Richard', '0', 'Smith, Zadie', 'Morton, Kate', 'Zusak, Markus', 'Binchy, Maeve', 'Harris, Robert', 'Oliver, Jamie', 'Collins, Suzanne', 'Pelzer, Dave', 'Oliver, Jamie']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Author_name \n",
    "Auth=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[3]\")\n",
    "for i in Auth:\n",
    "    if i.text is None :\n",
    "        Author_name.append(\"--\") \n",
    "    else:\n",
    "        Author_name.append(i.text)\n",
    "print(len(Author_name),Author_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5531a3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Crime, Thriller & Adventure', \"Children's Fiction\", \"Children's Fiction\", \"Children's Fiction\", 'Romance & Sagas', \"Children's Fiction\", \"Children's Fiction\", \"Children's Fiction\", 'Crime, Thriller & Adventure', \"Children's Fiction\", 'Romance & Sagas', 'Young Adult Fiction', 'Crime, Thriller & Adventure', 'Romance & Sagas', 'Crime, Thriller & Adventure', 'Young Adult Fiction', 'Crime, Thriller & Adventure', 'Young Adult Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'Popular Science', 'Crime, Thriller & Adventure', 'Young Adult Fiction', 'Picture Books', 'Picture Books', 'Food & Drink: General', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Humour: Collections & General', 'General & Literary Fiction', 'Autobiography: General', 'General & Literary Fiction', 'Biography: The Arts', 'Autobiography: General', 'Picture Books', 'Autobiography: General', 'General & Literary Fiction', 'Young Adult Fiction', 'General & Literary Fiction', 'Science Fiction & Fantasy', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'General & Literary Fiction', 'General & Literary Fiction', 'Fitness & Diet', 'General & Literary Fiction', \"Children's Fiction\", 'Crime, Thriller & Adventure', 'Fitness & Diet', 'Young Adult Fiction', 'Usage & Writing Guides', 'Food & Drink: General', 'General & Literary Fiction', 'Young Adult Fiction', 'General & Literary Fiction', 'Young Adult Fiction', 'General & Literary Fiction', 'Popular Culture & Media: General Interest', 'Autobiography: The Arts', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'Science Fiction & Fantasy', 'Current Affairs & Issues', 'Crime, Thriller & Adventure', 'Autobiography: The Arts', 'General & Literary Fiction', 'Autobiography: The Arts', 'Travel Writing', 'Food & Drink: General', 'General & Literary Fiction', 'National & Regional Cuisine', 'Fitness & Diet', 'Travel Writing', 'Crime, Thriller & Adventure', 'General & Literary Fiction', 'Food & Drink: General', 'General & Literary Fiction', 'General & Literary Fiction', 'Picture Books', 'General & Literary Fiction', 'Autobiography: The Arts', 'Popular Science', \"Children's Annuals\", 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Food & Drink: General', 'Young Adult Fiction', 'Biography: General', 'Food & Drink: General']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Genre \n",
    "gen=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[6]\")\n",
    "for i in gen:\n",
    "    if i.text is None :\n",
    "        Genre.append(\"--\") \n",
    "    else:\n",
    "        Genre.append(i.text)\n",
    "print(len(Genre),Genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37f27018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Transworld', 'Bloomsbury', 'Bloomsbury', 'Bloomsbury', 'Random House', 'Bloomsbury', 'Bloomsbury', 'Bloomsbury', 'Transworld', 'Bloomsbury', 'Random House', 'Little, Brown Book', 'Quercus', 'Random House', 'Transworld', 'Little, Brown Book', 'Transworld', 'Little, Brown Book', 'Pan Macmillan', 'Random House', 'Transworld', 'Transworld', 'Quercus', 'Little, Brown Book', 'Penguin', 'Pan Macmillan', 'Penguin', 'Bloomsbury', 'Hodder & Stoughton', 'Bloomsbury', 'Quercus', 'Random House', 'Random House', 'Pan Macmillan', 'Penguin', 'Random House', 'Random House', 'Canongate', 'HarperCollins', 'Orion', 'Pan Macmillan', 'HarperCollins', 'Random House', 'Scholastic Ltd.', 'Orion', 'Bloomsbury', 'Penguin', 'HarperCollins', 'Random House', 'Little, Brown Book', 'Headline', 'HarperCollins', 'Penguin', 'Orion', 'Bloomsbury', 'Random House', 'Random House', 'Scholastic Ltd.', 'Profile Books Group', 'Random House', 'Transworld', 'Random House Childrens Books G', 'Hodder & Stoughton', 'Scholastic Ltd.', 'Random House', 'HarperCollins', 'Random House', 'Penguin', 'Random House', 'HarperCollins', 'Penguin', 'Headline', 'Little, Brown Book', 'HarperCollins', 'Transworld', 'Transworld', 'Penguin', 'Pan Macmillan', 'Penguin', 'Transworld', 'Transworld', 'Random House', 'Headline', 'Random House', 'Transworld', 'Penguin', 'Pan Macmillan', 'Penguin', 'Hodder & Stoughton', 'Transworld', 'D.C. Thomson', 'Penguin', 'Pan Macmillan', 'Transworld', 'Orion', 'Random House', 'Penguin', 'Scholastic Ltd.', 'Orion', 'Penguin']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Publisher \n",
    "pub=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[5]\")\n",
    "for i in pub:\n",
    "    if i.text is None :\n",
    "        Publisher.append(\"--\") \n",
    "    else:\n",
    "        Publisher.append(i.text)\n",
    "print(len(Publisher),Publisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e027c13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['5,094,805', '4,475,152', '4,200,654', '4,179,479', '3,758,936', '3,583,215', '3,484,047', '3,377,906', '3,193,946', '2,950,264', '2,479,784', '2,315,405', '2,233,570', '2,193,928', '2,183,031', '2,152,737', '2,062,145', '2,052,876', '2,005,598', '1,979,552', '1,928,900', '1,852,919', '1,814,784', '1,787,118', '1,783,535', '1,781,269', '1,743,266', '1,629,119', '1,616,068', '1,583,992', '1,555,135', '1,546,886', '1,539,428', '1,508,205', '1,489,403', '1,352,318', '1,310,207', '1,310,176', '1,231,957', '1,217,712', '1,208,711', '1,204,058', '1,184,967', '1,181,503', '1,181,093', '1,153,181', '1,132,336', '1,130,802', '1,126,337', '1,115,549', '1,108,328', '1,107,379', '1,104,403', '1,092,349', '1,090,847', '1,087,262', '1,054,196', '1,037,160', '1,023,688', '1,015,956', '1,009,873', '1,004,414', '1,003,780', '1,002,314', '998,213', '992,846', '986,753', '986,115', '970,509', '967,466', '963,353', '962,515', '959,496', '956,114', '945,640', '931,312', '925,425', '924,695', '906,968', '905,086', '890,847', '869,671', '869,659', '862,602', '856,540', '845,858', '842,535', '828,215', '820,563', '816,907', '816,585', '815,586', '814,370', '809,641', '808,900', '807,311', '794,201', '792,187', '791,507', '791,095']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Volumes_sold \n",
    "vs=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[4]\")\n",
    "for i in vs:\n",
    "    if i.text is None :\n",
    "        Volumes_sold.append(\"--\") \n",
    "    else:\n",
    "        Volumes_sold.append(i.text)\n",
    "print(len(Volumes_sold),Volumes_sold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70af49aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Volumes_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>5,094,805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>Children's Fiction</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>4,475,152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>Children's Fiction</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>4,200,654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>Children's Fiction</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>4,179,479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "      <td>Random House</td>\n",
       "      <td>3,758,936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "      <td>Random House</td>\n",
       "      <td>807,311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>794,201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>792,187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>Biography: General</td>\n",
       "      <td>Orion</td>\n",
       "      <td>791,507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>791,095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_name       Author_name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "                          Genre        Publisher Volumes_sold  \n",
       "0   Crime, Thriller & Adventure       Transworld    5,094,805  \n",
       "1            Children's Fiction       Bloomsbury    4,475,152  \n",
       "2            Children's Fiction       Bloomsbury    4,200,654  \n",
       "3            Children's Fiction       Bloomsbury    4,179,479  \n",
       "4               Romance & Sagas     Random House    3,758,936  \n",
       "..                          ...              ...          ...  \n",
       "95   General & Literary Fiction     Random House      807,311  \n",
       "96        Food & Drink: General          Penguin      794,201  \n",
       "97          Young Adult Fiction  Scholastic Ltd.      792,187  \n",
       "98           Biography: General            Orion      791,507  \n",
       "99        Food & Drink: General          Penguin      791,095  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Book=pd.DataFrame([])\n",
    "Book['Book_name']=Book_name\n",
    "Book['Author_name']=Author_name\n",
    "Book['Genre']=Genre\n",
    "Book['Publisher']=Publisher\n",
    "Book['Volumes_sold']=Volumes_sold\n",
    "Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cfe1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e366bb7",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "449a25a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.imdb.com/search/title/?title_type=tv_series&sort=num_votes,desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a9fbb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 ['1. Game of Thrones', '2. Breaking Bad', '3. Stranger Things', '4. Friends', '5. The Walking Dead', '6. Sherlock', '7. The Big Bang Theory', '8. Dexter', '9. How I Met Your Mother', '10. The Office', '11. True Detective', '12. Peaky Blinders', '13. Better Call Saul', '14. The Boys', '15. Black Mirror', '16. Rick and Morty', '17. Lost', '18. The Mandalorian', '19. Vikings', '20. Prison Break', '21. The Witcher', '22. Squid Game', '23. Westworld', '24. House of Cards', '25. Money Heist', '26. House', '27. The Last of Us', '28. Attack on Titan', '29. Supernatural', '30. Modern Family', '31. Suits', '32. Daredevil', '33. Narcos', '34. The Sopranos', '35. Arrow', '36. Dark', '37. The Simpsons', '38. Fargo', '39. Mr. Robot', '40. Loki', '41. South Park', '42. The Wire', '43. Death Note', '44. The Flash', '45. House of the Dragon', '46. Family Guy', '47. Homeland', '48. Avatar: The Last Airbender', '49. Brooklyn Nine-Nine', '50. Wednesday']\n"
     ]
    }
   ],
   "source": [
    "Name=[]\n",
    "Year_span=[]\n",
    "Genres=[]\n",
    "Run_time=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#scraping the Name \n",
    "mname=driver.find_elements(By.XPATH, '//div[@class=\"sc-be6f1408-0 gVGktK\"]/div[1]/a[1]/h3')\n",
    "for i in mname:\n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "print(len(Name),Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d2f81f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 ['2011–2019', '2008–2013', '2016–2025', '1994–2004', '2010–2022', '2010–2017', '2007–2019', '2006–2013', '2005–2014', '2005–2013', '2014–', '2013–2022', '2015–2022', '2019–', '2011–', '2013–', '2004–2010', '2019–', '2013–2020', '2005–2017', '2019–', '2021–', '2016–2022', '2013–2018', '2017–2021', '2004–2012', '2023–', '2013–2023', '2005–2020', '2009–2020', '2011–2019', '2015–2018', '2015–2017', '1999–2007', '2012–2020', '2017–2020', '1989–', '2014–2024', '2015–2019', '2021–2023', '1997–', '2002–2008', '2006–2007', '2014–2023', '2022–', '1999–2025', '2011–2020', '2005–2008', '2013–2021', '2022–']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Year_span \n",
    "ys=driver.find_elements(By.XPATH, '//div[@class=\"sc-be6f1408-0 gVGktK\"]/div[2]/span[1]')\n",
    "for i in ys:\n",
    "    if i.text is None :\n",
    "        Year_span.append(\"--\") \n",
    "    else:\n",
    "        Year_span.append(i.text)\n",
    "print(len(Year_span),Year_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "94bce712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 ['9.2', '9.5', '8.7', '8.9', '8.1', '9.1', '8.2', '8.7', '8.3', '9.0', '8.9', '8.8', '9.0', '8.7', '8.7', '9.1', '8.3', '8.7', '8.5', '8.3', '8.0', '8.0', '8.5', '8.6', '8.2', '8.7', '8.8', '9.1', '8.4', '8.5', '8.4', '8.6', '8.8', '9.2', '7.5', '8.7', '8.7', '8.9', '8.5', '8.2', '8.7', '9.3', '8.9', '7.5', '8.4', '8.2', '8.3', '9.3', '8.4', '8.1']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "Ratings = []\n",
    "#scraping the Ratings \n",
    "rate=driver.find_elements(By.XPATH, '//span[@class=\"ipc-rating-star ipc-rating-star--base ipc-rating-star--imdb ratingGroup--imdb-rating\"]')\n",
    "for i in rate:\n",
    "    if i.text is None :\n",
    "        Ratings.append(\"--\") \n",
    "    else:\n",
    "        rating_text = re.split(r'\\s',i.text)[0]\n",
    "        Ratings.append(rating_text)\n",
    "print(len(Ratings),Ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "521d6db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 ['2,258,992', '2,106,387', '1,317,933', '1,077,265', '1,070,306', '988,220', '860,010', '758,803', '723,320', '698,370', '640,893', '636,162', '635,337', '633,315', '632,179', '593,634', '589,638', '579,553', '575,202', '574,272', '564,493', '530,232', '529,228', '527,910', '525,863', '504,036', '500,632', '497,554', '478,459', '476,350', '471,180', '470,792', '465,025', '461,751', '444,563', '436,978', '432,638', '415,451', '414,751', '405,937', '402,999', '372,513', '371,946', '366,724', '362,904', '361,637', '359,014', '356,635', '355,602', '352,533']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "Votes = []\n",
    "\n",
    "#scraping the Votes \n",
    "v=driver.find_elements(By.XPATH, '//div[@class=\"sc-f24f1c5c-0 cPpOqU\"]')\n",
    "for i in v:\n",
    "    if i.text is None :\n",
    "        Votes.append(\"--\") \n",
    "    else:\n",
    "        vote_text = i.text.replace(\"Votes\", \"\")\n",
    "        Votes.append(vote_text.strip())\n",
    "        \n",
    "print(len(Votes),Votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "acf4c905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Game of Thrones</td>\n",
       "      <td>2011–2019</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,258,992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Breaking Bad</td>\n",
       "      <td>2008–2013</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2,106,387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. Stranger Things</td>\n",
       "      <td>2016–2025</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,317,933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. Friends</td>\n",
       "      <td>1994–2004</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1,077,265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. The Walking Dead</td>\n",
       "      <td>2010–2022</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,070,306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6. Sherlock</td>\n",
       "      <td>2010–2017</td>\n",
       "      <td>9.1</td>\n",
       "      <td>988,220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7. The Big Bang Theory</td>\n",
       "      <td>2007–2019</td>\n",
       "      <td>8.2</td>\n",
       "      <td>860,010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8. Dexter</td>\n",
       "      <td>2006–2013</td>\n",
       "      <td>8.7</td>\n",
       "      <td>758,803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9. How I Met Your Mother</td>\n",
       "      <td>2005–2014</td>\n",
       "      <td>8.3</td>\n",
       "      <td>723,320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10. The Office</td>\n",
       "      <td>2005–2013</td>\n",
       "      <td>9.0</td>\n",
       "      <td>698,370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11. True Detective</td>\n",
       "      <td>2014–</td>\n",
       "      <td>8.9</td>\n",
       "      <td>640,893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12. Peaky Blinders</td>\n",
       "      <td>2013–2022</td>\n",
       "      <td>8.8</td>\n",
       "      <td>636,162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13. Better Call Saul</td>\n",
       "      <td>2015–2022</td>\n",
       "      <td>9.0</td>\n",
       "      <td>635,337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14. The Boys</td>\n",
       "      <td>2019–</td>\n",
       "      <td>8.7</td>\n",
       "      <td>633,315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15. Black Mirror</td>\n",
       "      <td>2011–</td>\n",
       "      <td>8.7</td>\n",
       "      <td>632,179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16. Rick and Morty</td>\n",
       "      <td>2013–</td>\n",
       "      <td>9.1</td>\n",
       "      <td>593,634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17. Lost</td>\n",
       "      <td>2004–2010</td>\n",
       "      <td>8.3</td>\n",
       "      <td>589,638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18. The Mandalorian</td>\n",
       "      <td>2019–</td>\n",
       "      <td>8.7</td>\n",
       "      <td>579,553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19. Vikings</td>\n",
       "      <td>2013–2020</td>\n",
       "      <td>8.5</td>\n",
       "      <td>575,202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20. Prison Break</td>\n",
       "      <td>2005–2017</td>\n",
       "      <td>8.3</td>\n",
       "      <td>574,272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21. The Witcher</td>\n",
       "      <td>2019–</td>\n",
       "      <td>8.0</td>\n",
       "      <td>564,493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22. Squid Game</td>\n",
       "      <td>2021–</td>\n",
       "      <td>8.0</td>\n",
       "      <td>530,232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23. Westworld</td>\n",
       "      <td>2016–2022</td>\n",
       "      <td>8.5</td>\n",
       "      <td>529,228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24. House of Cards</td>\n",
       "      <td>2013–2018</td>\n",
       "      <td>8.6</td>\n",
       "      <td>527,910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25. Money Heist</td>\n",
       "      <td>2017–2021</td>\n",
       "      <td>8.2</td>\n",
       "      <td>525,863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26. House</td>\n",
       "      <td>2004–2012</td>\n",
       "      <td>8.7</td>\n",
       "      <td>504,036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27. The Last of Us</td>\n",
       "      <td>2023–</td>\n",
       "      <td>8.8</td>\n",
       "      <td>500,632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28. Attack on Titan</td>\n",
       "      <td>2013–2023</td>\n",
       "      <td>9.1</td>\n",
       "      <td>497,554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29. Supernatural</td>\n",
       "      <td>2005–2020</td>\n",
       "      <td>8.4</td>\n",
       "      <td>478,459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30. Modern Family</td>\n",
       "      <td>2009–2020</td>\n",
       "      <td>8.5</td>\n",
       "      <td>476,350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31. Suits</td>\n",
       "      <td>2011–2019</td>\n",
       "      <td>8.4</td>\n",
       "      <td>471,180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32. Daredevil</td>\n",
       "      <td>2015–2018</td>\n",
       "      <td>8.6</td>\n",
       "      <td>470,792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33. Narcos</td>\n",
       "      <td>2015–2017</td>\n",
       "      <td>8.8</td>\n",
       "      <td>465,025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34. The Sopranos</td>\n",
       "      <td>1999–2007</td>\n",
       "      <td>9.2</td>\n",
       "      <td>461,751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35. Arrow</td>\n",
       "      <td>2012–2020</td>\n",
       "      <td>7.5</td>\n",
       "      <td>444,563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36. Dark</td>\n",
       "      <td>2017–2020</td>\n",
       "      <td>8.7</td>\n",
       "      <td>436,978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37. The Simpsons</td>\n",
       "      <td>1989–</td>\n",
       "      <td>8.7</td>\n",
       "      <td>432,638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38. Fargo</td>\n",
       "      <td>2014–2024</td>\n",
       "      <td>8.9</td>\n",
       "      <td>415,451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39. Mr. Robot</td>\n",
       "      <td>2015–2019</td>\n",
       "      <td>8.5</td>\n",
       "      <td>414,751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40. Loki</td>\n",
       "      <td>2021–2023</td>\n",
       "      <td>8.2</td>\n",
       "      <td>405,937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41. South Park</td>\n",
       "      <td>1997–</td>\n",
       "      <td>8.7</td>\n",
       "      <td>402,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42. The Wire</td>\n",
       "      <td>2002–2008</td>\n",
       "      <td>9.3</td>\n",
       "      <td>372,513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43. Death Note</td>\n",
       "      <td>2006–2007</td>\n",
       "      <td>8.9</td>\n",
       "      <td>371,946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44. The Flash</td>\n",
       "      <td>2014–2023</td>\n",
       "      <td>7.5</td>\n",
       "      <td>366,724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45. House of the Dragon</td>\n",
       "      <td>2022–</td>\n",
       "      <td>8.4</td>\n",
       "      <td>362,904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46. Family Guy</td>\n",
       "      <td>1999–2025</td>\n",
       "      <td>8.2</td>\n",
       "      <td>361,637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47. Homeland</td>\n",
       "      <td>2011–2020</td>\n",
       "      <td>8.3</td>\n",
       "      <td>359,014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48. Avatar: The Last Airbender</td>\n",
       "      <td>2005–2008</td>\n",
       "      <td>9.3</td>\n",
       "      <td>356,635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49. Brooklyn Nine-Nine</td>\n",
       "      <td>2013–2021</td>\n",
       "      <td>8.4</td>\n",
       "      <td>355,602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50. Wednesday</td>\n",
       "      <td>2022–</td>\n",
       "      <td>8.1</td>\n",
       "      <td>352,533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name  Year_span Ratings      Votes\n",
       "0               1. Game of Thrones  2011–2019     9.2  2,258,992\n",
       "1                  2. Breaking Bad  2008–2013     9.5  2,106,387\n",
       "2               3. Stranger Things  2016–2025     8.7  1,317,933\n",
       "3                       4. Friends  1994–2004     8.9  1,077,265\n",
       "4              5. The Walking Dead  2010–2022     8.1  1,070,306\n",
       "5                      6. Sherlock  2010–2017     9.1    988,220\n",
       "6           7. The Big Bang Theory  2007–2019     8.2    860,010\n",
       "7                        8. Dexter  2006–2013     8.7    758,803\n",
       "8         9. How I Met Your Mother  2005–2014     8.3    723,320\n",
       "9                   10. The Office  2005–2013     9.0    698,370\n",
       "10              11. True Detective      2014–     8.9    640,893\n",
       "11              12. Peaky Blinders  2013–2022     8.8    636,162\n",
       "12            13. Better Call Saul  2015–2022     9.0    635,337\n",
       "13                    14. The Boys      2019–     8.7    633,315\n",
       "14                15. Black Mirror      2011–     8.7    632,179\n",
       "15              16. Rick and Morty      2013–     9.1    593,634\n",
       "16                        17. Lost  2004–2010     8.3    589,638\n",
       "17             18. The Mandalorian      2019–     8.7    579,553\n",
       "18                     19. Vikings  2013–2020     8.5    575,202\n",
       "19                20. Prison Break  2005–2017     8.3    574,272\n",
       "20                 21. The Witcher      2019–     8.0    564,493\n",
       "21                  22. Squid Game      2021–     8.0    530,232\n",
       "22                   23. Westworld  2016–2022     8.5    529,228\n",
       "23              24. House of Cards  2013–2018     8.6    527,910\n",
       "24                 25. Money Heist  2017–2021     8.2    525,863\n",
       "25                       26. House  2004–2012     8.7    504,036\n",
       "26              27. The Last of Us      2023–     8.8    500,632\n",
       "27             28. Attack on Titan  2013–2023     9.1    497,554\n",
       "28                29. Supernatural  2005–2020     8.4    478,459\n",
       "29               30. Modern Family  2009–2020     8.5    476,350\n",
       "30                       31. Suits  2011–2019     8.4    471,180\n",
       "31                   32. Daredevil  2015–2018     8.6    470,792\n",
       "32                      33. Narcos  2015–2017     8.8    465,025\n",
       "33                34. The Sopranos  1999–2007     9.2    461,751\n",
       "34                       35. Arrow  2012–2020     7.5    444,563\n",
       "35                        36. Dark  2017–2020     8.7    436,978\n",
       "36                37. The Simpsons      1989–     8.7    432,638\n",
       "37                       38. Fargo  2014–2024     8.9    415,451\n",
       "38                   39. Mr. Robot  2015–2019     8.5    414,751\n",
       "39                        40. Loki  2021–2023     8.2    405,937\n",
       "40                  41. South Park      1997–     8.7    402,999\n",
       "41                    42. The Wire  2002–2008     9.3    372,513\n",
       "42                  43. Death Note  2006–2007     8.9    371,946\n",
       "43                   44. The Flash  2014–2023     7.5    366,724\n",
       "44         45. House of the Dragon      2022–     8.4    362,904\n",
       "45                  46. Family Guy  1999–2025     8.2    361,637\n",
       "46                    47. Homeland  2011–2020     8.3    359,014\n",
       "47  48. Avatar: The Last Airbender  2005–2008     9.3    356,635\n",
       "48          49. Brooklyn Nine-Nine  2013–2021     8.4    355,602\n",
       "49                   50. Wednesday      2022–     8.1    352,533"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TV_Series=pd.DataFrame([])\n",
    "TV_Series['Name']=Name\n",
    "TV_Series['Year_span']=Year_span\n",
    "#TV_Series['Run_time']=Run_time\n",
    "#TV_Series['Genres']=Genres\n",
    "TV_Series['Ratings']=Ratings\n",
    "TV_Series['Votes']=Votes\n",
    "TV_Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4a2da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94d5af09",
   "metadata": {},
   "source": [
    "# 8. Details of Datasets from UCI machine learning repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "53bb7751",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7fa1c71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_Name=[]\n",
    "Data_Type=[]\n",
    "Task=[]\n",
    "Attribute_Type=[]\n",
    "No_of_Instances=[]\n",
    "No_of_Attribute=[]\n",
    "Year=[]\n",
    "\n",
    "\n",
    "search_1 = driver.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]')       # Locating page foe top videos by xpath\n",
    "search_1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "755ca838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ['Iris', 'Dry Bean Dataset', 'Heart Disease', 'Rice (Cammeo and Osmancik)', 'Adult', 'Raisin', 'Wine', 'Breast Cancer Wisconsin (Diagnostic)', 'Wine Quality', 'Diabetes']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Dataset_Name \n",
    "dname=driver.find_elements(By.XPATH, '//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "for i in dname:\n",
    "    if i.text is None :\n",
    "        Dataset_Name.append(\"--\") \n",
    "    else:\n",
    "        Dataset_Name.append(i.text)\n",
    "print(len(Dataset_Name),Dataset_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8fdced33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ['Tabular', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Tabular', 'Multivariate', 'Multivariate', 'Multivariate, Time-Series']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Data_Type \n",
    "dtype=driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[2]/span')\n",
    "for i in dtype:\n",
    "    if i.text is None :\n",
    "        Data_Type.append(\"--\") \n",
    "    else:\n",
    "        Data_Type.append(i.text)\n",
    "print(len(Data_Type),Data_Type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "29f30404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ['Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification, Regression', 'Classification']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Task \n",
    "t=driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[1]/span[1]')\n",
    "for i in t:\n",
    "    if i.text is None :\n",
    "        Task.append(\"--\") \n",
    "    else:\n",
    "        Task.append(i.text)\n",
    "print(len(Task),Task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "217cafee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ['150 Instances', '13.61K Instances', '303 Instances', '3.81K Instances', '48.84K Instances', '900 Instances', '178 Instances', '569 Instances', '4.9K Instances', '1 Instances']\n"
     ]
    }
   ],
   "source": [
    "#scraping the No_of_Instances \n",
    "noi=driver.find_elements(By.XPATH, '//div[@class=\"relative col-span-8 sm:col-span-7\"]/div/div[3]/span')\n",
    "for i in noi:\n",
    "    if i.text is None :\n",
    "        No_of_Instances.append(\"--\") \n",
    "    else:\n",
    "        No_of_Instances.append(i.text)\n",
    "print(len(No_of_Instances),No_of_Instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "08ed6d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ['4 Features', '16 Features', '13 Features', '7 Features', '14 Features', '8 Features', '13 Features', '30 Features', '12 Features', '20 Features']\n"
     ]
    }
   ],
   "source": [
    "#scraping the No_of_Attribute \n",
    "noa=driver.find_elements(By.XPATH, '//div[@class=\"relative col-span-8 sm:col-span-7\"]/div/div[4]/span')\n",
    "for i in noa:\n",
    "    if i.text is None :\n",
    "        No_of_Attribute.append(\"--\") \n",
    "    else:\n",
    "        No_of_Attribute.append(i.text)\n",
    "print(len(No_of_Attribute),No_of_Attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7a049ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_Name</th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>No_of_Instances</th>\n",
       "      <th>No_of_Attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>7 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Raisin</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>900 Instances</td>\n",
       "      <td>8 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>4.9K Instances</td>\n",
       "      <td>12 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>1 Instances</td>\n",
       "      <td>20 Features</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset_Name                  Data_Type  \\\n",
       "0                                  Iris                    Tabular   \n",
       "1                      Dry Bean Dataset               Multivariate   \n",
       "2                         Heart Disease               Multivariate   \n",
       "3            Rice (Cammeo and Osmancik)               Multivariate   \n",
       "4                                 Adult               Multivariate   \n",
       "5                                Raisin               Multivariate   \n",
       "6                                  Wine                    Tabular   \n",
       "7  Breast Cancer Wisconsin (Diagnostic)               Multivariate   \n",
       "8                          Wine Quality               Multivariate   \n",
       "9                              Diabetes  Multivariate, Time-Series   \n",
       "\n",
       "                         Task   No_of_Instances No_of_Attribute  \n",
       "0              Classification     150 Instances      4 Features  \n",
       "1              Classification  13.61K Instances     16 Features  \n",
       "2              Classification     303 Instances     13 Features  \n",
       "3              Classification   3.81K Instances      7 Features  \n",
       "4              Classification  48.84K Instances     14 Features  \n",
       "5              Classification     900 Instances      8 Features  \n",
       "6              Classification     178 Instances     13 Features  \n",
       "7              Classification     569 Instances     30 Features  \n",
       "8  Classification, Regression    4.9K Instances     12 Features  \n",
       "9              Classification       1 Instances     20 Features  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UCI=pd.DataFrame([])\n",
    "UCI['Dataset_Name']=Dataset_Name\n",
    "UCI['Data_Type']=Data_Type\n",
    "UCI['Task']=Task\n",
    "\n",
    "UCI['No_of_Instances']=No_of_Instances\n",
    "UCI['No_of_Attribute']=No_of_Attribute\n",
    "\n",
    "UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80edd69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
